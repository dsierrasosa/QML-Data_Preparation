{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "loose-budget",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "import sklearn.datasets as skd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qiskit.aqua.components.optimizers import SPSA\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.aqua.algorithms import QSVM, VQC\n",
    "from qiskit.providers.ibmq import least_busy\n",
    "from qiskit import BasicAer\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute\n",
    "from sklearn.datasets import make_blobs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "palestinian-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBMQ.load_account()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "casual-ocean",
   "metadata": {},
   "outputs": [],
   "source": [
    "# provider = IBMQ.get_provider(hub='ibm-q-research')\n",
    "# provider.backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "received-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = make_blobs(n_samples=70, centers=2, n_features=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "opposite-vegetarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Scatter plot\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0][y==0], X[:, 1][y==0], c='r', marker='^', edgecolors='k', label=\"train 0\")\n",
    "plt.scatter(X[:, 0][y==1], X[:, 1][y==1], c='b', marker='^', edgecolors='k', label=\"train 1\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "confirmed-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train, sample_test, label_train, label_test = train_test_split(X, y, test_size=0.2,  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-election",
   "metadata": {},
   "source": [
    "# Quantum SVM|VQC - Qiskit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "underlying-header",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [r'B', r'A']#[r'A', r'B']\n",
    "training_dataset = {key : np.array(sample_train[label_train == k, :])[:] for k, key in enumerate(class_labels)}\n",
    "test_dataset = {key : np.array(sample_test[label_test == k, :])[:] for k, key in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bacterial-composite",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42\n",
    "feature_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "applied-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the feature map\n",
    "feature_map = ZZFeatureMap(feature_dimension=feature_dim, reps=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "outside-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend =  BasicAer.get_backend('statevector_simulator')#'statevector_simulator''qasm_simulator'\n",
    "quantum_instance = QuantumInstance(backend, seed_simulator=random_seed, seed_transpiler=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "lesser-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "qsvm = QSVM(feature_map = feature_map, training_dataset=training_dataset, test_dataset=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "perfect-constant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         6\n",
      "           1       1.00      0.62      0.77         8\n",
      "\n",
      "    accuracy                           0.79        14\n",
      "   macro avg       0.83      0.81      0.78        14\n",
      "weighted avg       0.86      0.79      0.78        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = qsvm.run(quantum_instance)\n",
    "# print(\"testing success ratio: \", result['testing_accuracy'])\n",
    "print(classification_report(label_test , qsvm.predict(sample_test , quantum_instance)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "entire-engine",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SPSA(maxiter=40, c0=4.0, skip_calibration=True)\n",
    "var_form = TwoLocal(feature_dim, ['ry', 'rz'], 'cz', reps=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "british-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "vqc= VQC(optimizer = optimizer,feature_map = feature_map,var_form = var_form, training_dataset=training_dataset, test_dataset=test_dataset,)# Variational "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "super-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vqc.run(quantum_instance)\n",
    "# print(f'Testing success ratio: {result[\"testing_accuracy\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "statistical-covering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.50      0.50         6\n",
      "           1       0.62      0.62      0.62         8\n",
      "\n",
      "    accuracy                           0.57        14\n",
      "   macro avg       0.56      0.56      0.56        14\n",
      "weighted avg       0.57      0.57      0.57        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test , vqc.predict(sample_test , quantum_instance)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instrumental-diana",
   "metadata": {},
   "source": [
    "# Classic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "characteristic-participant",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "civil-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(sample_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "durable-bedroom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           1.00        14\n",
      "   macro avg       1.00      1.00      1.00        14\n",
      "weighted avg       1.00      1.00      1.00        14\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, clf.predict(sample_test) , zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-stable",
   "metadata": {},
   "source": [
    "# VQC - Amplitude Encoding Mottonen Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "olive-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(x, n): # x is an array to be encoded, n is the number of qubits\n",
    "    numerator = 0 # numerator of expression for beta\n",
    "    denominator = 0 # denominator of expression for beta\n",
    "    beta = []\n",
    "    for k in range (1, n+1): # s is k in Mikko\n",
    "        for j in range(1, 1+2**(n-k)):\n",
    "            for l in range(1, 1+2**(k-1)):\n",
    "                #print(\"num: k, j, l: \", k, j, l)\n",
    "                numerator = numerator + (x[((((2*j-1)*(2**(k-1)))+l))-1]**2)\n",
    "            for l in range(1, 1+2**(k)):\n",
    "                #print(\"den: k, j, l: \", k, j, l)\n",
    "                denominator = denominator + (x[((((j-1)*(2**(k)))+l))-1]**2)\n",
    "            if k != n:\n",
    "                beta.append(np.arcsin(np.sqrt(numerator)/np.sqrt(denominator)))\n",
    "                beta.append(-1*np.arcsin(np.sqrt(numerator)/np.sqrt(denominator)))\n",
    "            else:\n",
    "                beta.append(2*np.arcsin(np.sqrt(numerator)/np.sqrt(denominator)))\n",
    "            numerator = 0\n",
    "            denominator = 0\n",
    "    return np.fliplr([beta])[0] # return the last entry in reverse order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "grateful-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray_code(n):\n",
    "    m = n-1 \n",
    "    xgates = []\n",
    "    for i in range(1, m):\n",
    "        xgates_temp = []\n",
    "        for k in range(1, 2+i):\n",
    "            xgates_temp.append(n-k-1)\n",
    "        xgates.append(xgates_temp)\n",
    "    \n",
    "    # stagger gates\n",
    "    num_stag = n-4 # for n=3->0, n=4->0, n=5->1, n=6->2\n",
    "    #num_gaps = ((2**n)-1)-len(xgates)\n",
    "    num_gap = len(xgates)-2\n",
    "    if n>4:\n",
    "        for j in range(0, num_stag):\n",
    "            if j==0:\n",
    "                for i in range(0, num_gap):\n",
    "                    xgates.insert(j+2+2*i, xgates[j]) #j=0\n",
    "            else: # j>0 -> 2nd+ staggerization  \n",
    "                for k in range(0, j):\n",
    "                    xgates.insert(j+4, xgates[j]) #j=1\n",
    "                    xgates.insert(j+5, xgates[j-1]) #j=0\n",
    "    \n",
    "    # repeat second half\n",
    "    s = len(xgates)-1\n",
    "    for i in range(0, s):\n",
    "        xgates.append(xgates[s-1-i])\n",
    "        \n",
    "    return xgates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "norman-writer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create circuit\n",
    "def amp_enc_qc(A, qc, n):           \n",
    "    \n",
    "    # arbitrary transformation of the data (can remove but will need to change hyperparams)\n",
    "    A = 2*A\n",
    "\n",
    "    # always apply first rotation\n",
    "    qc.ry(A[0],0)\n",
    "                \n",
    "    #xgates = []\n",
    "    ang = 1\n",
    "    for i in range(1, n):\n",
    "        num_sub_blocks = 2**(i)\n",
    "        \n",
    "        # get xgates from gray code\n",
    "        xgate_idx = 0\n",
    "        xgates = []\n",
    "        if i<6:\n",
    "            xgates = gray_code(i+1)\n",
    "        elif i>=6:\n",
    "            if i==6:\n",
    "                xgates_6 = gray_code(6)\n",
    "            #xgates_6 = gray_code(6)\n",
    "            else: \n",
    "                xgates_6 = last_xgates\n",
    "            \n",
    "            for k in range(0, len(xgates_6)):\n",
    "                xgates_temp = []\n",
    "                for j in range(0, len(xgates_6[k])):\n",
    "                    temp = 1+xgates_6[k][j]\n",
    "                    xgates_temp.append(temp)\n",
    "                xgates.append(xgates_temp)\n",
    "            full_gates = [x for x in range(0, i)]\n",
    "            xgates.append(full_gates)    \n",
    "            s = len(xgates)-1\n",
    "            for k in range(0, s):\n",
    "                xgates.append(xgates[s-1-k])\n",
    "            last_xgates = xgates.copy()\n",
    "\n",
    "        # add initialization gates\n",
    "        if i>1:\n",
    "            for k in range(i-1):\n",
    "                qc.x(k)\n",
    "                        \n",
    "        for j in range(1, num_sub_blocks+1):\n",
    "            for r in range(1, 3):\n",
    "                if i==1: # if on 2 qubits\n",
    "                    qc.cx(0, 1)\n",
    "                elif i==2: # if on 3 qubits\n",
    "                    qc.ccx(0, 1, 2)\n",
    "                elif i==3: # if on 4 qubits\n",
    "                    qc.mcx([0, 1, 2], 3)\n",
    "                elif i==4:\n",
    "                    qc.mcx([0, 1, 2, 3], 4) \n",
    "                else:\n",
    "                    q_list = []\n",
    "                    for k in range(0, i):\n",
    "                        q_list.append(k)\n",
    "                    qc.mcx(q_list, i)\n",
    "   \n",
    "                qc.ry(A[ang], i)\n",
    "                ang += 1\n",
    "                \n",
    "            #qc.barrier()\n",
    "\n",
    "            # add x gates\n",
    "            if (j%2)==1: #if j is odd\n",
    "                qc.x(i-1)\n",
    "            else: #j is even\n",
    "                if ((i>1)&(xgate_idx<len(xgates))):\n",
    "                    for l in range(0, len(xgates[xgate_idx])):\n",
    "                        qc.x(xgates[xgate_idx][l])\n",
    "                        #print('l: ',l)\n",
    "                    xgate_idx += 1\n",
    "   \n",
    "    # account for the extra x-gate discrepancy in the state prep code for 2 qubits\n",
    "        for l in range(i):\n",
    "            if i>1:\n",
    "                qc.x(l)\n",
    "    if n==2:\n",
    "        qc.x(0)\n",
    "    \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-terrorist",
   "metadata": {},
   "source": [
    "## Parameterized Circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "prompt-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct variational circuit\n",
    "def var_classifier(qc, var, n):\n",
    "    weights = var\n",
    "    j=1\n",
    "    for W in weights:\n",
    "        for i in range(n):\n",
    "            # parameterized layers\n",
    "            qc.u3(W[i, 0], W[i, 1], W[i, 2], i)\n",
    "        if n==2:\n",
    "            # alternating control nots\n",
    "            if (j%2)==1:\n",
    "                qc.cx(0, 1)\n",
    "            else:\n",
    "                qc.cx(1, 0)\n",
    "            j+=1\n",
    "        elif n>2:\n",
    "            for i in range(n-1):\n",
    "                qc.cx(i, i+1)\n",
    "            qc.cx(0, n-1)\n",
    "    return qc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "spoken-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run circuit\n",
    "def execute_circuit(n, params, angles, x=None, bias=0.0, shots=1000, use_angles=True):\n",
    "    if not use_angles:\n",
    "        angles = get_angles(x, n)\n",
    "        angles = np.nan_to_num(angles)\n",
    "    \n",
    "    # create circuit\n",
    "    q = QuantumRegister(n)\n",
    "    c = ClassicalRegister(1)\n",
    "    qc = QuantumCircuit(q, c)\n",
    "    \n",
    "    # Mottonen method\n",
    "    qc = amp_enc_qc(angles, qc, n)\n",
    "    \n",
    "    # divide and conquer\n",
    "    #qc = _generate_circuit(angles.tolist(), qc, q)\n",
    "\n",
    "    # parameterized circuit\n",
    "    qc = var_classifier(qc, params, n)\n",
    "        \n",
    "    qc.measure(0, c)\n",
    "        \n",
    "    result = execute(qc, backend, shots=shots).result()\n",
    "    counts = result.get_counts(qc)\n",
    "    result = np.zeros(2)\n",
    "    for key in counts:\n",
    "        result[int(key, 2)] = counts[key]\n",
    "    result /= shots\n",
    "    \n",
    "    return result[1] + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "touched-poultry",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ctrl_U(param, qc, q, a, ctrl, n):\n",
    "    order = True # keeps track of alternating cX gates\n",
    "    for i in range(param.shape[0]): # for each parameterized layer\n",
    "        for j in range(n):\n",
    "            # add parameterized gates\n",
    "            qc.cu3(param[i][j][0], param[i][j][1], param[i][j][2], a[0], q[j], ctrl_state=ctrl)\n",
    "        if n==2:\n",
    "            if order:\n",
    "                qc.ccx(a[0], q[0], q[1]) # add controlled-nots\n",
    "            else:\n",
    "                qc.ccx(a[0], q[1], q[0])\n",
    "            order = not order\n",
    "        elif n>2:\n",
    "            for k in range(n-1):\n",
    "                qc.ccx(a[0], q[k], q[k+1])\n",
    "            qc.ccx(a[0], q[0], q[n-1])\n",
    "    return qc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "rotary-architect",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_inner_prod(n, param1, param2, angles, shots=1000):\n",
    "    \"\"\"Returns Re{<circuit(param2)|sigma_z|circuit(param1)>}\"\"\"\n",
    "    a = QuantumRegister(1) # ancilla\n",
    "    q = QuantumRegister(n)\n",
    "    c = ClassicalRegister(1)\n",
    "    qc = QuantumCircuit(q, c)\n",
    "    \n",
    "    # Mottonen method\n",
    "    qc = amp_enc_qc(angles, qc, n)\n",
    "    \n",
    "    # divide and conquer\n",
    "    #qc = _generate_circuit(angles.tolist(), qc, q)\n",
    "    \n",
    "    # add ancilla register\n",
    "    qc.add_register(a)\n",
    "    qc.h(a[0])\n",
    "    \n",
    "    # (sigma_z)(U)|psi>\n",
    "    #qc = ctrl_U(param1, qc, q, a, 0) #\n",
    "    #qc.cz(a[0], q[0], ctrl_state=0) #\n",
    "    qc = ctrl_U(param1, qc, q, a, 1, n) #\n",
    "    qc.cz(a[0], q[0], ctrl_state=1) #\n",
    "    qc.x(a[0]) #\n",
    "    \n",
    "    # <psi|(dU)\n",
    "    qc = ctrl_U(param2, qc, q, a, 1, n)\n",
    "    \n",
    "    qc.x(a[0]) #\n",
    "    \n",
    "    qc.h(a[0])\n",
    "    qc.measure(a[0], c)\n",
    "        \n",
    "    result = execute(qc, backend, shots=shots).result()\n",
    "    counts = result.get_counts(qc)\n",
    "    result = np.zeros(2)\n",
    "    for key in counts:\n",
    "        result[int(key, 2)] = counts[key]\n",
    "    result /= shots\n",
    "    return (2*result[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "later-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imag_inner_prod(n, param1, param2, angles, shots=1000):\n",
    "    \"\"\"Returns Im{<circuit(param2)|sigma_z|circuit(param1)>}\"\"\"\n",
    "    a = QuantumRegister(1) # ancilla\n",
    "    q = QuantumRegister(n)\n",
    "    c = ClassicalRegister(1)\n",
    "    qc = QuantumCircuit(q, c)\n",
    "            \n",
    "    # Mottonen method\n",
    "    qc = amp_enc_qc(angles, qc, n)\n",
    "    \n",
    "    # divide and conquer\n",
    "    #qc = _generate_circuit(angles.tolist(), qc, q)\n",
    "    \n",
    "    # add ancilla register\n",
    "    qc.add_register(a)\n",
    "    qc.h(a[0])\n",
    "        \n",
    "    # (sigma_z)(U)|psi> #\n",
    "    #qc = ctrl_U(param1, qc, q, a, 0) #\n",
    "    #qc.cz(a[0], q[0], ctrl_state=0) #\n",
    "    qc = ctrl_U(param1, qc, q, a, 1, n) #\n",
    "    qc.cz(a[0], q[0], ctrl_state=1) #\n",
    "    qc.x(a[0]) #\n",
    "    \n",
    "    # <psi|(dU)\n",
    "    qc = ctrl_U(param2, qc, q, a, 1, n)\n",
    "    \n",
    "    qc.x(a[0]) #\n",
    "    \n",
    "    # u1 rotation adds a coefficient of \"i\" to the second ket (i.e. ancilla qubit=1)\n",
    "    qc.u1(np.pi/2, a[0])\n",
    "    qc.h(a[0])\n",
    "    qc.measure(a[0], c)\n",
    "        \n",
    "    result = execute(qc, backend, shots=shots).result()\n",
    "    counts = result.get_counts(qc)\n",
    "    result = np.zeros(2)\n",
    "    for key in counts:\n",
    "        result[int(key, 2)] = counts[key]\n",
    "    result /= shots\n",
    "    return -(2*result[0]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "broad-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(n, params, angles, label, bias=0):\n",
    "    grads = np.zeros_like(params)\n",
    "    imag = imag_inner_prod(n, params, params, angles) # needed to calc the imag component of inner product below\n",
    "    for i in range(params.shape[0]):\n",
    "        for j in range(params.shape[1]):            \n",
    "            params_bra = np.copy(params)\n",
    "                        \n",
    "            # theta\n",
    "            params_bra[i,j,0] += np.pi\n",
    "            grads[i,j,0] = -0.5*real_inner_prod(n, params, params_bra, angles)\n",
    "            params_bra[i,j,0] -= np.pi # reset for next param below\n",
    "            \n",
    "            # phi\n",
    "            params_bra[i,j,1] += np.pi\n",
    "            grads[i,j,1] = 0.5*(imag_inner_prod(n, params, params_bra, angles)-imag)\n",
    "            params_bra[i,j,1] -= np.pi\n",
    "            \n",
    "            # lambda\n",
    "            params_bra[i,j,2] += np.pi\n",
    "            grads[i,j,2] = 0.5*(imag_inner_prod(n, params, params_bra, angles)-imag)\n",
    "            params_bra[i,j,2] -= np.pi\n",
    "            \n",
    "    p = execute_circuit(n, params, angles, bias=bias) \n",
    "    grad_bias = (p-label) / (p*(1-p))\n",
    "    grads *= grad_bias\n",
    "    return grads, grad_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "varying-night",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n, layers, params_init, bias_init, batch_size, learning_rate, momentum, iterations, feats_train, Y_train, feats_val, Y_val, features, Y):\n",
    "    var = np.copy(params_init)\n",
    "    bias = bias_init\n",
    "    v = np.zeros_like(var)\n",
    "    v_bias = 0\n",
    "    \n",
    "    num_train = len(feats_train)\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        # Update the weights by one optimizer step\n",
    "        batch_index = np.random.randint(0, num_train, (batch_size,))\n",
    "        feats_train_batch = feats_train[batch_index]\n",
    "        Y_train_batch = Y_train[batch_index]\n",
    "        grads = np.zeros_like(var)\n",
    "        grad_bias = 0\n",
    "        var_corrected = var + momentum*v\n",
    "        bias_corrected = bias + momentum*v_bias\n",
    "        for j in range(batch_size):\n",
    "            g, g_bias = gradients(n, var_corrected, feats_train_batch[j], Y_train_batch[j], bias)\n",
    "            grads += g/batch_size\n",
    "            grad_bias += g_bias/batch_size\n",
    "\n",
    "        v = momentum*v - learning_rate*grads\n",
    "        v_bias = momentum*v_bias - learning_rate*grad_bias\n",
    "\n",
    "        var += v\n",
    "        bias += v_bias\n",
    "\n",
    "        # Compute predictions on train and validation set\n",
    "        prob_train = np.array([execute_circuit(n, var, angles=f, bias=bias) for f in feats_train])\n",
    "        prob_val = np.array([execute_circuit(n, var, angles=f, bias=bias) for f in feats_val])\n",
    "        pred_train = predict(prob_train)\n",
    "        pred_val = predict(prob_val)\n",
    "\n",
    "        # Compute accuracy on train and validation set\n",
    "        acc_train = accuracy(Y_train, pred_train)\n",
    "        acc_val = accuracy(Y_val, pred_val)\n",
    "\n",
    "        print(\"Iter: {:5d} | Loss: {:0.7f} | Acc train: {:0.7f} | Acc validation: {:0.7f} \"\n",
    "              \"\".format(it + 1, cost(n, var, features, Y), acc_train, acc_val))\n",
    "    \n",
    "    return var, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biological-holiday",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "utility-script",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(prob):\n",
    "    return (prob >= 0.5)*1\n",
    "\n",
    "def binary_crossentropy(labels, pred):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, pred):\n",
    "        loss = loss - l*np.log(np.max([p, 1e-8]))\n",
    "    loss = loss/len(labels)\n",
    "    return loss\n",
    "\n",
    "def square_loss(labels, pred):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, pred):\n",
    "        loss = loss + (l-p)**2\n",
    "    loss = loss/len(labels)\n",
    "    return loss \n",
    "\n",
    "def cost(n, params, features, labels):\n",
    "    pred = [execute_circuit(n, params, angles=f) for f in features]\n",
    "    return binary_crossentropy(labels, pred)\n",
    "\n",
    "def accuracy(labels, pred):\n",
    "    loss = 0\n",
    "    for l, p in zip(labels, pred):\n",
    "        if abs(l-p) < 1e-5:\n",
    "            loss = loss+1\n",
    "    loss = loss/len(labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-champagne",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "intelligent-fusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextPowerOf2(n):\n",
    "    p = 1\n",
    "    if (n and not(n & (n - 1))):\n",
    "        return n\n",
    "    while (p < n) :\n",
    "        p <<= 1     \n",
    "    return p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "valuable-detective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextPowerOf2(len(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "centered-university",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-105-438c362d41ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpadding_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.3\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnextPowerOf2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36mones\u001b[1;34m(shape, dtype, order)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m     \"\"\"\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m     \u001b[0mmultiarray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unsafe'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "padding_X = 0.3 * np.ones((len(X), np.zeros((nextPowerOf2(len(X[0])),1))-len(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "robust-unemployment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First X sample (original)  : [-7.38705277 -9.30936606  7.55557285  0.57421589  2.75398778  0.3\n",
      "  0.3         0.3       ]\n",
      "First X sample (normalized): [-0.51438866 -0.64824667  0.52612336  0.03998484  0.19177067  0.02089014\n",
      "  0.02089014  0.02089014]\n"
     ]
    }
   ],
   "source": [
    "# padding_X = np.zeros((nextPowerOf2(len(X[0])),1))\n",
    "padding_X = 0.3*np.ones((len(X), nextPowerOf2(len(X[0]))-len(X[0])))\n",
    "\n",
    "X_pad = np.c_[np.c_[X, padding_X], np.zeros((len(X), 0))]\n",
    "X_pad\n",
    "print(\"First X sample (original)  :\", X_pad[0])\n",
    "\n",
    "# normalize each input\n",
    "normalization = np.sqrt(np.sum(X**2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(\"First X sample (normalized):\", X_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "deluxe-protest",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits\n",
    "n = 3\n",
    "num_qubits = n # needed for D&C\n",
    "\n",
    "# angles for state preparation are new features; impute nans\n",
    "features = np.array([get_angles(x, n) for x in X_norm])\n",
    "features = np.nan_to_num(features)\n",
    "\n",
    "# divide and conquer\n",
    "#features = np.array([recursive_compute_beta(x, betas=[]) for x in X_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "tutorial-commander",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "# number of samples\n",
    "num_data = len(y) # 100\n",
    "\n",
    "# number of training samples\n",
    "num_train = int(0.75*num_data) # 75\n",
    "\n",
    "# randomly split into train, validation sets\n",
    "index = np.random.permutation(range(num_data))\n",
    "feats_train = features[index[:num_train]]\n",
    "Y_train = y[index[:num_train]]\n",
    "feats_val = features[index[num_train:]]\n",
    "Y_val = y[index[num_train:]]\n",
    "\n",
    "# We need these later for plotting\n",
    "X_train = X[index[:num_train]]\n",
    "X_val = X[index[num_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "centered-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Loss: 0.5957759 | Acc train: 0.0769231 | Acc validation: 0.0555556 \n",
      "Iter:     2 | Loss: 0.6169725 | Acc train: 0.2307692 | Acc validation: 0.0555556 \n",
      "Iter:     3 | Loss: 0.6281000 | Acc train: 0.5384615 | Acc validation: 0.3888889 \n",
      "Iter:     4 | Loss: 0.6614992 | Acc train: 0.5384615 | Acc validation: 0.3888889 \n",
      "Iter:     5 | Loss: 0.6740265 | Acc train: 0.5384615 | Acc validation: 0.3888889 \n",
      "Iter:     6 | Loss: 0.7033934 | Acc train: 0.5384615 | Acc validation: 0.3888889 \n"
     ]
    }
   ],
   "source": [
    "# number of parameterized layers\n",
    "layers = 2 #1\n",
    "batch_size = 10\n",
    "iterations = 6\n",
    "\n",
    "# initial parameters\n",
    "params_init = np.random.randn(layers, n, 3)*0.01\n",
    "bias_init = 0.01\n",
    "learning_rate = 0.01\n",
    "momentum = 0.9\n",
    "\n",
    "# set backend to run \n",
    "backend = BasicAer.get_backend('qasm_simulator')\n",
    "\n",
    "# train model\n",
    "var, bias = train_model(n, layers, params_init, bias_init, batch_size, learning_rate, momentum, iterations, feats_train, Y_train, feats_val, Y_val, features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-floor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
