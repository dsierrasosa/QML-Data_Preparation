{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from qiskit import IBMQ\n",
    "import sklearn.datasets as skd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from qiskit.aqua.components.optimizers import SPSA\n",
    "from qiskit.circuit.library import ZZFeatureMap, TwoLocal\n",
    "from qiskit.aqua.algorithms import QSVM, VQC\n",
    "from qiskit.providers.ibmq import least_busy\n",
    "from qiskit import Aer\n",
    "from qiskit.aqua import QuantumInstance\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute\n",
    "from sklearn.datasets import make_blobs\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = pd.read_csv('heart.csv')\n",
    "ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='output', ylabel='count'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = 'output', data =ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x720 with 8 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "col = ['sex', 'cp', 'fbs', 'restecg','exng', 'slp', 'caa', 'thall',]\n",
    "c = 1\n",
    "for i in col:\n",
    "    if c < 9:\n",
    "        plt.subplot(2,4,c)\n",
    "        sns.countplot(x = i,data =ds,hue = 'output')\n",
    "        plt.xlabel(i)\n",
    "    c += 1\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining dependent and independent variables\n",
    "X = ds.drop('output', axis=1)\n",
    "y = ds['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, _, y, _ = train_test_split(X, y, test_size=0.5,  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X.values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.9521966 ,  0.68100522,  1.97312292, ..., -2.27457861,\n",
       "        -0.71442887, -2.14887271],\n",
       "       [-1.91531289,  0.68100522,  1.00257707, ..., -2.27457861,\n",
       "        -0.71442887, -0.51292188],\n",
       "       [-1.47415758, -1.46841752,  0.03203122, ...,  0.97635214,\n",
       "        -0.71442887, -0.51292188],\n",
       "       ...,\n",
       "       [ 1.50364073,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         1.24459328,  1.12302895],\n",
       "       [ 0.29046364,  0.68100522, -0.93851463, ..., -0.64911323,\n",
       "         0.26508221,  1.12302895],\n",
       "       [ 0.29046364, -1.46841752,  0.03203122, ..., -0.64911323,\n",
       "         0.26508221, -0.51292188]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotator\n",
    "from typing import Callable, List, Optional, Tuple, Union\n",
    "from math import atan2\n",
    "def rotate_matrix_nd(bs,degrees):\n",
    "    ang = np.deg2rad(degrees)\n",
    "    dim = np.shape(bs)[0]\n",
    "    Rot_mat = np.eye(dim)\n",
    "    for k in range(0,dim-2):\n",
    "        for l in range(dim-1,k,-1):\n",
    "            a = atan2(bs[l,k],bs[l-1,k])\n",
    "            R = np.eye(dim)\n",
    "            R_temp = np.array([[np.cos(a),np.sin(a)],[-1*np.sin(a),np.cos(a)]])\n",
    "            tmp = l - 1\n",
    "            R[tmp:tmp+R_temp.shape[0],tmp:tmp+R_temp.shape[0]] = R_temp\n",
    "            bs=np.matmul(R,bs)\n",
    "            Rot_mat = np.matmul(R,Rot_mat)\n",
    "    R = np.eye(dim)\n",
    "    R[dim-2:dim,dim-2:dim] = np.array([[np.cos(ang),-1*np.sin(ang)],[np.sin(ang),np.cos(ang)]])\n",
    "    Rot_mat = np.matmul(np.linalg.inv(Rot_mat),np.matmul(R,Rot_mat))\n",
    "    return Rot_mat\n",
    "#     Rot_mat = np.linalg.lstsq(Rot_mat,np.matmul(R,Rot_mat))\n",
    "    \n",
    "    \n",
    "#     R = np.array([[np.cos(angle), -np.sin(angle)], [np.sin(angle), np.cos(angle)]])\n",
    "#     o = np.atleast_2d(origin)\n",
    "#     p = np.atleast_2d(points)\n",
    "#     return np.squeeze((R @ (p.T - o.T) + o.T).T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 13\n",
    "v = np.logical_or(np.eye(dim),np.fliplr(np.eye(dim))).astype(int)\n",
    "v = v[:,:-2]\n",
    "# v = np.eye(dim)[:,:-2]\n",
    "# v[-2][0] = 1\n",
    "# v[-1][1] = 1\n",
    "rot = rotate_matrix_nd(v,-15)\n",
    "\n",
    "# print(rot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.84386611,  0.78470102,  1.83571009, ..., -2.13716578,\n",
       "        -0.81812466, -2.04054222],\n",
       "       [-1.83612886,  0.75148252,  1.10301879, ..., -2.37502033,\n",
       "        -0.78490616, -0.5921059 ],\n",
       "       [-1.40748138, -1.48992398,  0.11660727, ...,  0.89177609,\n",
       "        -0.69292241, -0.57959808],\n",
       "       ...,\n",
       "       [ 1.43704203,  0.6608252 , -1.02299239, ..., -0.56463548,\n",
       "         1.26477331,  1.18962766],\n",
       "       [ 0.2698416 ,  0.53634742, -0.96467285, ..., -0.62295502,\n",
       "         0.40974001,  1.14365099],\n",
       "       [ 0.34479314, -1.42376974,  0.10094597, ..., -0.71802799,\n",
       "         0.22043443, -0.56725137]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX = np.empty((0,dim))\n",
    "for point in X:\n",
    "    tmp_point = np.matmul(rot,np.atleast_2d(point).T)\n",
    "    tmp_point = np.atleast_2d(tmp_point).T\n",
    "    XX = np.append(XX, tmp_point,axis=0)\n",
    "XX    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train, sample_test, label_train, label_test = train_test_split(XX, y, test_size=0.25,  shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227, 13)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classic SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(gamma='scale')\n",
    "clf.fit(sample_train, label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.86      0.87        35\n",
      "           1       0.88      0.90      0.89        41\n",
      "\n",
      "    accuracy                           0.88        76\n",
      "   macro avg       0.88      0.88      0.88        76\n",
      "weighted avg       0.88      0.88      0.88        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(label_test, clf.predict(sample_test) , zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VQC - Amplitude Encoding Mottonen Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nextPowerOf2(n):\n",
    "    p = 1\n",
    "    if (n and not(n & (n - 1))):\n",
    "        return n\n",
    "    while (p < n) :\n",
    "        p <<= 1     \n",
    "    return p;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First X sample (original)  : [ 0.84386611  0.78470102  1.83571009  0.89548967 -0.56804912  2.69281731\n",
      " -1.00583187 -0.28293652 -0.38491514  0.95580416 -2.13716578 -0.81812466\n",
      " -2.04054222  0.3         0.3         0.3       ]\n",
      "First X sample (normalized): [ 0.17004435  0.15812221  0.36990717  0.18044682 -0.11446548  0.54261968\n",
      " -0.20268147 -0.0570135  -0.07756283  0.19260057 -0.43065239 -0.16485728\n",
      " -0.41118214  0.06045189  0.06045189  0.06045189]\n"
     ]
    }
   ],
   "source": [
    "# padding_X = np.zeros((nextPowerOf2(len(X[0])),1))\n",
    "X = XX\n",
    "y = y.values\n",
    "\n",
    "padding_X = 0.3*np.ones((len(X), nextPowerOf2(len(X[0]))-len(X[0])))\n",
    "\n",
    "X_pad = np.c_[np.c_[X, padding_X], np.zeros((len(X), 0))]\n",
    "X_pad\n",
    "print(\"First X sample (original)  :\", X_pad[0])\n",
    "\n",
    "# normalize each input\n",
    "normalization = np.sqrt(np.sum(X**2, -1))\n",
    "X_norm = (X_pad.T / normalization).T\n",
    "print(\"First X sample (normalized):\", X_norm[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of qubits\n",
    "n = 4\n",
    "num_qubits = n # needed for D&C\n",
    "\n",
    "# angles for state preparation are new features; impute nans\n",
    "features = np.array([funcs.get_angles(x, n) for x in X_norm])\n",
    "features = np.nan_to_num(features)\n",
    "\n",
    "# divide and conquer\n",
    "#features = np.array([recursive_compute_beta(x, betas=[]) for x in X_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# number of samples\n",
    "num_data = len(y) # 100\n",
    "\n",
    "# number of training samples\n",
    "num_train = int(0.75*num_data) # 75\n",
    "\n",
    "# randomly split into train, validation sets\n",
    "# index = np.random.permutation(range(num_data))\n",
    "# feats_train = features[index[:num_train]]\n",
    "# Y_train = y[index[:num_train]]\n",
    "# feats_val = features[index[num_train:]]\n",
    "# Y_val = y[index[num_train:]]\n",
    "\n",
    "feats_train, feats_val, Y_train, Y_val = train_test_split(features, y, test_size=0.25,  shuffle=True, random_state=42)\n",
    "\n",
    "# We need these later for plotting\n",
    "# X_train = X[index[:num_train]]\n",
    "# X_val = X[index[num_train:]]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:     1 | Loss: 1.5671648 | Acc train: 0.5066079 | Acc validation: 0.4605263 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.97      0.62        35\n",
      "           1       0.50      0.02      0.05        41\n",
      "\n",
      "    accuracy                           0.46        76\n",
      "   macro avg       0.48      0.50      0.34        76\n",
      "weighted avg       0.48      0.46      0.31        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.98      0.64       103\n",
      "           1       0.88      0.11      0.20       124\n",
      "\n",
      "    accuracy                           0.51       227\n",
      "   macro avg       0.68      0.55      0.42       227\n",
      "weighted avg       0.70      0.51      0.40       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     2 | Loss: 1.4871905 | Acc train: 0.5154185 | Acc validation: 0.4868421 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.97      0.64        35\n",
      "           1       0.75      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.49        76\n",
      "   macro avg       0.61      0.52      0.38        76\n",
      "weighted avg       0.62      0.49      0.36        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.96      0.64       103\n",
      "           1       0.82      0.15      0.25       124\n",
      "\n",
      "    accuracy                           0.52       227\n",
      "   macro avg       0.65      0.55      0.44       227\n",
      "weighted avg       0.67      0.52      0.43       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     3 | Loss: 1.4758735 | Acc train: 0.5198238 | Acc validation: 0.4868421 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.97      0.64        35\n",
      "           1       0.75      0.07      0.13        41\n",
      "\n",
      "    accuracy                           0.49        76\n",
      "   macro avg       0.61      0.52      0.38        76\n",
      "weighted avg       0.62      0.49      0.36        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.64       103\n",
      "           1       0.83      0.15      0.26       124\n",
      "\n",
      "    accuracy                           0.52       227\n",
      "   macro avg       0.66      0.56      0.45       227\n",
      "weighted avg       0.67      0.52      0.43       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     4 | Loss: 1.4986404 | Acc train: 0.5286344 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.97      0.64        35\n",
      "           1       0.80      0.10      0.17        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.64      0.53      0.41        76\n",
      "weighted avg       0.65      0.50      0.39        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.96      0.65       103\n",
      "           1       0.84      0.17      0.28       124\n",
      "\n",
      "    accuracy                           0.53       227\n",
      "   macro avg       0.67      0.57      0.47       227\n",
      "weighted avg       0.68      0.53      0.45       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     5 | Loss: 1.6085363 | Acc train: 0.5286344 | Acc validation: 0.5131579 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.97      0.65        35\n",
      "           1       0.83      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.51        76\n",
      "   macro avg       0.66      0.55      0.43        76\n",
      "weighted avg       0.67      0.51      0.41        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.65       103\n",
      "           1       0.81      0.18      0.29       124\n",
      "\n",
      "    accuracy                           0.53       227\n",
      "   macro avg       0.65      0.56      0.47       227\n",
      "weighted avg       0.67      0.53      0.45       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     6 | Loss: 1.6009263 | Acc train: 0.5374449 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        35\n",
      "           1       0.71      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.60      0.53      0.42        76\n",
      "weighted avg       0.61      0.50      0.40        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.65       103\n",
      "           1       0.83      0.19      0.31       124\n",
      "\n",
      "    accuracy                           0.54       227\n",
      "   macro avg       0.66      0.57      0.48       227\n",
      "weighted avg       0.68      0.54      0.47       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     7 | Loss: 1.4748889 | Acc train: 0.5330396 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        35\n",
      "           1       0.71      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.60      0.53      0.42        76\n",
      "weighted avg       0.61      0.50      0.40        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65       103\n",
      "           1       0.80      0.19      0.31       124\n",
      "\n",
      "    accuracy                           0.53       227\n",
      "   macro avg       0.65      0.57      0.48       227\n",
      "weighted avg       0.66      0.53      0.46       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     8 | Loss: 1.4932866 | Acc train: 0.5462555 | Acc validation: 0.5131579 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.91      0.63        35\n",
      "           1       0.70      0.17      0.27        41\n",
      "\n",
      "    accuracy                           0.51        76\n",
      "   macro avg       0.59      0.54      0.45        76\n",
      "weighted avg       0.60      0.51      0.44        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.94      0.65       103\n",
      "           1       0.82      0.22      0.34       124\n",
      "\n",
      "    accuracy                           0.55       227\n",
      "   macro avg       0.66      0.58      0.50       227\n",
      "weighted avg       0.67      0.55      0.48       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:     9 | Loss: 1.5221678 | Acc train: 0.5330396 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        35\n",
      "           1       0.71      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.60      0.53      0.42        76\n",
      "weighted avg       0.61      0.50      0.40        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65       103\n",
      "           1       0.80      0.19      0.31       124\n",
      "\n",
      "    accuracy                           0.53       227\n",
      "   macro avg       0.65      0.57      0.48       227\n",
      "weighted avg       0.66      0.53      0.46       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    10 | Loss: 1.5639896 | Acc train: 0.5374449 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        35\n",
      "           1       0.71      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.60      0.53      0.42        76\n",
      "weighted avg       0.61      0.50      0.40        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.95      0.65       103\n",
      "           1       0.83      0.19      0.31       124\n",
      "\n",
      "    accuracy                           0.54       227\n",
      "   macro avg       0.66      0.57      0.48       227\n",
      "weighted avg       0.68      0.54      0.47       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    11 | Loss: 1.4546288 | Acc train: 0.5330396 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63        35\n",
      "           1       0.71      0.12      0.21        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.60      0.53      0.42        76\n",
      "weighted avg       0.61      0.50      0.40        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65       103\n",
      "           1       0.80      0.19      0.31       124\n",
      "\n",
      "    accuracy                           0.53       227\n",
      "   macro avg       0.65      0.57      0.48       227\n",
      "weighted avg       0.66      0.53      0.46       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    12 | Loss: 1.5300628 | Acc train: 0.5418502 | Acc validation: 0.5131579 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.64        35\n",
      "           1       0.75      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.51        76\n",
      "   macro avg       0.62      0.54      0.44        76\n",
      "weighted avg       0.63      0.51      0.43        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.95      0.65       103\n",
      "           1       0.83      0.20      0.32       124\n",
      "\n",
      "    accuracy                           0.54       227\n",
      "   macro avg       0.67      0.58      0.49       227\n",
      "weighted avg       0.68      0.54      0.47       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    13 | Loss: 1.5742497 | Acc train: 0.5374449 | Acc validation: 0.5000000 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.91      0.63        35\n",
      "           1       0.67      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.57      0.53      0.43        76\n",
      "weighted avg       0.58      0.50      0.42        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.94      0.65       103\n",
      "           1       0.81      0.20      0.32       124\n",
      "\n",
      "    accuracy                           0.54       227\n",
      "   macro avg       0.65      0.57      0.49       227\n",
      "weighted avg       0.67      0.54      0.47       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    14 | Loss: 1.5923435 | Acc train: 0.5418502 | Acc validation: 0.4868421 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.89      0.61        35\n",
      "           1       0.60      0.15      0.24        41\n",
      "\n",
      "    accuracy                           0.49        76\n",
      "   macro avg       0.53      0.52      0.42        76\n",
      "weighted avg       0.54      0.49      0.41        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       103\n",
      "           1       0.79      0.22      0.34       124\n",
      "\n",
      "    accuracy                           0.54       227\n",
      "   macro avg       0.65      0.57      0.50       227\n",
      "weighted avg       0.66      0.54      0.48       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    15 | Loss: 1.5310010 | Acc train: 0.5506608 | Acc validation: 0.5263158 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.91      0.64        35\n",
      "           1       0.73      0.20      0.31        41\n",
      "\n",
      "    accuracy                           0.53        76\n",
      "   macro avg       0.61      0.55      0.47        76\n",
      "weighted avg       0.62      0.53      0.46        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       103\n",
      "           1       0.81      0.23      0.36       124\n",
      "\n",
      "    accuracy                           0.55       227\n",
      "   macro avg       0.65      0.58      0.51       227\n",
      "weighted avg       0.67      0.55      0.49       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    16 | Loss: 1.1755588 | Acc train: 0.5638767 | Acc validation: 0.5921053 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.26      0.37        35\n",
      "           1       0.58      0.88      0.70        41\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.61      0.57      0.53        76\n",
      "weighted avg       0.61      0.59      0.55        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.18      0.28       103\n",
      "           1       0.56      0.88      0.69       124\n",
      "\n",
      "    accuracy                           0.56       227\n",
      "   macro avg       0.56      0.53      0.48       227\n",
      "weighted avg       0.56      0.56      0.50       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    17 | Loss: 1.1587236 | Acc train: 0.5462555 | Acc validation: 0.5394737 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.54      1.00      0.70        41\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.27      0.50      0.35        76\n",
      "weighted avg       0.29      0.54      0.38        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       103\n",
      "           1       0.55      1.00      0.71       124\n",
      "\n",
      "    accuracy                           0.55       227\n",
      "   macro avg       0.27      0.50      0.35       227\n",
      "weighted avg       0.30      0.55      0.39       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nemo/anaconda3/envs/qiskit/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:    18 | Loss: 1.1594215 | Acc train: 0.5462555 | Acc validation: 0.5394737 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.54      1.00      0.70        41\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.27      0.50      0.35        76\n",
      "weighted avg       0.29      0.54      0.38        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       103\n",
      "           1       0.55      1.00      0.71       124\n",
      "\n",
      "    accuracy                           0.55       227\n",
      "   macro avg       0.27      0.50      0.35       227\n",
      "weighted avg       0.30      0.55      0.39       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    19 | Loss: 1.1611686 | Acc train: 0.5462555 | Acc validation: 0.5394737 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.54      1.00      0.70        41\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.27      0.50      0.35        76\n",
      "weighted avg       0.29      0.54      0.38        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       103\n",
      "           1       0.55      1.00      0.71       124\n",
      "\n",
      "    accuracy                           0.55       227\n",
      "   macro avg       0.27      0.50      0.35       227\n",
      "weighted avg       0.30      0.55      0.39       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Iter:    20 | Loss: 1.1519596 | Acc train: 0.5594714 | Acc validation: 0.5394737 \n",
      "\n",
      " --------------------------------TEST SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        35\n",
      "           1       0.54      1.00      0.70        41\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.27      0.50      0.35        76\n",
      "weighted avg       0.29      0.54      0.38        76\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      " --------------------------------TRAIN SET----------------------------------\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06       103\n",
      "           1       0.55      1.00      0.71       124\n",
      "\n",
      "    accuracy                           0.56       227\n",
      "   macro avg       0.78      0.51      0.38       227\n",
      "weighted avg       0.76      0.56      0.41       227\n",
      " \n",
      "--------------------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# number of parameterized layers\n",
    "layers = 5 #1\n",
    "batch_size = 20\n",
    "iterations = 20\n",
    "\n",
    "# initial parameters\n",
    "params_init = np.random.randn(layers, n, 3)*0.01\n",
    "bias_init = 0.01\n",
    "learning_rate = 0.01\n",
    "momentum = 0.1\n",
    "\n",
    "# set backend to run \n",
    "backend = Aer.get_backend('qasm_simulator')\n",
    "\n",
    "# train model\n",
    "var, bias, Y_val, pred_val = funcs.train_model(n, layers, params_init, bias_init, batch_size, learning_rate, momentum, iterations, feats_train, Y_train, feats_val, Y_val, features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.89      0.63        35\n",
      "           1       0.69      0.22      0.33        41\n",
      "\n",
      "    accuracy                           0.53        76\n",
      "   macro avg       0.59      0.55      0.48        76\n",
      "weighted avg       0.60      0.53      0.47        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Y_val, pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
